{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather images with Unsplash API\n",
    "Goal: Use 'Unsplash API' to make basic search queries in form of HTTP requests to the api server and fetch specified data of images/photos in form of JSON. \n",
    "<br><br>To do this: \n",
    "<ol>\n",
    "    <li> Initialization: Set up environment for necessary API key(s) and end point</li>\n",
    "    <li> Query function: Define function for basic querying </li>\n",
    "    <li> Filtering function: Define function to filter based on some attribute of JSON. In this case it is created_date. </li>\n",
    "    <li> Composite functions: Use the basic functions as subroutines to get the result I need. \n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant imports\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables required for using Unsplash API\n",
    "ACCESS_KEY = \"JojQg5MlI4bH3scg1sQN4Am9-ytvq0Xw-eezzWx5tvE\"\n",
    "SECRET_KEY = \"trgN82fiIFdISXYIhnQscbgtI4jUuYhdDciwvmHV8-c\"\n",
    "END_POINT = \"https://api.unsplash.com/search/photos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic querying function \n",
    "def search_unsplash(query, page=1, per_page=10):\n",
    "    \"\"\"\n",
    "    Search for photos on Unsplash based on the given query.\n",
    "\n",
    "    Parameters:\n",
    "    - query (str): The search term to use for the query.\n",
    "    - page (int, optional): The page number to fetch. Default is 1.\n",
    "    - per_page (int, optional): Number of items per page. Default is 10.\n",
    "    \n",
    "    Returns:\n",
    "    - dict: JSON response from the Unsplash API containing details about \n",
    "            the photos that match the query, as well as metadata about \n",
    "            the search results.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        'Authorization': f'Client-ID {ACCESS_KEY}'\n",
    "    }\n",
    "    \n",
    "    params = {\n",
    "        'query': query,\n",
    "        'page': page,\n",
    "        'per_page': per_page\n",
    "    }\n",
    "    \n",
    "    response = requests.get(END_POINT, headers=headers, params=params)\n",
    "    response.raise_for_status()  # Check if the request was successful\n",
    "    return response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage, fetch the first 100 images when querying \"black lives matter\"\n",
    "# result = search_unsplash(\"black lives matter\", page=1, per_page=100)\n",
    "# print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter JSON response by date. \n",
    "def filter_by_date(json_response, start, end):\n",
    "    \"\"\"\n",
    "    Filters images from the JSON response based on their 'created_at' date.\n",
    "    \n",
    "    Parameters:\n",
    "    - json_response (dict): The JSON response from the Unsplash API.\n",
    "    - start (str): The start date in 'YYYY-MM-DD' format.\n",
    "    - end (str): The end date in 'YYYY-MM-DD' format.\n",
    "    \n",
    "    Returns:\n",
    "    - list: A list of images filtered by the date criteria.\n",
    "    \"\"\"\n",
    "    \n",
    "    filtered_images = []\n",
    "\n",
    "    # Convert start and end strings to date objects\n",
    "    start_date = datetime.strptime(start, \"%Y-%m-%d\").date()\n",
    "    end_date = datetime.strptime(end, \"%Y-%m-%d\").date()\n",
    "\n",
    "    for image in json_response.get(\"results\", []):\n",
    "        image_date_str = image.get(\"created_at\", \"\").split(\"T\")[0]  # Extract the date part\n",
    "        image_date = datetime.strptime(image_date_str, \"%Y-%m-%d\").date()\n",
    "\n",
    "        if start_date <= image_date <= end_date:\n",
    "            filtered_images.append(image)\n",
    "    \n",
    "    return filtered_images\n",
    "\n",
    "# Example usage:\n",
    "# result = search_unsplash(\"black lives matter\", page=1, per_page=100)\n",
    "# filtered_images = filter_by_date(result, \"2020-05-01\", \"2020-12-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get n images given a query and date range\n",
    "def query_in_date_range(query, start, end, count):\n",
    "    \"\"\"\n",
    "    Queries the Unsplash API for images based on the given search term and filters them by date.\n",
    "    \n",
    "    Parameters:\n",
    "    - query (str): The search term.\n",
    "    - start (str): The start date in 'YYYY-MM-DD' format.\n",
    "    - end (str): The end date in 'YYYY-MM-DD' format.\n",
    "    - count (int): The number of images to retrieve.\n",
    "    \n",
    "    Returns:\n",
    "    - str: A JSON string containing the list of images filtered by the date criteria.\n",
    "    \"\"\"\n",
    "    \n",
    "    collected_images = []\n",
    "    page = 1\n",
    "    per_page = 100  # Maximum allowed by most APIs for a single request\n",
    "\n",
    "    while len(collected_images) < count:\n",
    "        response = search_unsplash(query, page=page, per_page=per_page)\n",
    "        filtered = filter_by_date(response, start, end)\n",
    "        \n",
    "        collected_images.extend(filtered)\n",
    "        \n",
    "        # Check if we've collected enough images or if there are no more results\n",
    "        if len(filtered) == 0 or len(collected_images) >= count:\n",
    "            break\n",
    "        \n",
    "        page += 1\n",
    "\n",
    "    # Create a dictionary with the desired structure\n",
    "    response_data = {\n",
    "        'results': collected_images[:count],\n",
    "        'total': len(collected_images[:count])\n",
    "    }\n",
    "\n",
    "    # Convert the dictionary to a JSON string\n",
    "    return json.dumps(response_data)\n",
    "\n",
    "# Example usage:\n",
    "# json_response = query_in_date_range(\"black lives matter\", \"2020-05-01\", \"2020-12-31\", 100)\n",
    "# print(json_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function (for sanity check) containing dates of the images in json response. \n",
    "def list_of_dates_of_images(json_response) -> list:\n",
    "    \"\"\"\n",
    "    Extracts the 'created_at' dates from the given JSON response.\n",
    "    \n",
    "    Parameters:\n",
    "    - json_response (str): The JSON response containing image details.\n",
    "    \n",
    "    Returns:\n",
    "    - list: A list of 'created_at' dates for each image in the response.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Parse the JSON string to get a dictionary\n",
    "    data = json.loads(json_response)\n",
    "    \n",
    "    # Extract the 'created_at' date for each image\n",
    "    dates = [image['created_at'] for image in data.get('results', [])]\n",
    "    \n",
    "    return dates\n",
    "\n",
    "# Example usage:\n",
    "# json_response = query_in_date_range(\"black lives matter\", \"2020-05-01\", \"2020-12-31\", 100)\n",
    "# dates = list_of_dates_of_images(json_response)\n",
    "# print(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a json response, download images into 'downloads' folder. \n",
    "def download_images_from_json(json_response, download_folder='downloads'):\n",
    "    \"\"\"\n",
    "    Downloads images from the given JSON response.\n",
    "    \n",
    "    Parameters:\n",
    "    - json_response (str): The JSON response containing image URLs.\n",
    "    - download_folder (str, optional): The folder where images will be saved. Default is 'downloads'.\n",
    "    \n",
    "    Returns:\n",
    "    - list: A list of file paths where images were saved.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Parse the JSON string to get a dictionary\n",
    "    data = json.loads(json_response)\n",
    "    \n",
    "    # Create the download folder if it doesn't exist\n",
    "    if not os.path.exists(download_folder):\n",
    "        os.makedirs(download_folder)\n",
    "    \n",
    "    saved_files = []\n",
    "\n",
    "    # Add a loop counter for auto-indexing\n",
    "    for index, image in enumerate(data.get('results', []), start=1):\n",
    "        # Create a filename using the loop counter\n",
    "        filename = os.path.join(download_folder, f'image{index}.jpg')\n",
    "        \n",
    "        # Assuming the 'urls' field contains a 'full' subfield with the image URL\n",
    "        image_url = image['urls']['full']\n",
    "        \n",
    "        # Download the image\n",
    "        response = requests.get(image_url, stream=True)\n",
    "        response.raise_for_status()  # Raise an error for bad responses\n",
    "\n",
    "        # Save the image to the file\n",
    "        with open(filename, 'wb') as file:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                file.write(chunk)\n",
    "        \n",
    "        saved_files.append(filename)\n",
    "\n",
    "    return saved_files\n",
    "\n",
    "# Example usage:\n",
    "# json_response = query_in_date_range(\"black lives matter\", \"2020-05-01\", \"2020-12-31\", 100)\n",
    "# downloaded_files = download_images_from_json(json_response)\n",
    "# print(downloaded_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2020-06-03T13:12:16Z', '2020-06-16T11:50:43Z', '2020-06-13T20:46:58Z', '2020-11-26T01:02:09Z', '2020-06-06T23:28:20Z', '2020-10-31T16:14:23Z', '2020-06-03T13:06:08Z', '2020-06-02T02:49:45Z', '2020-06-10T19:35:16Z', '2020-06-13T08:18:15Z', '2020-06-11T15:01:16Z', '2020-06-01T16:57:29Z', '2020-06-08T13:16:05Z', '2020-10-11T17:21:12Z', '2020-06-03T13:06:08Z', '2020-06-19T01:34:38Z', '2020-06-08T14:21:41Z', '2020-06-25T03:26:47Z', '2020-06-24T02:50:38Z', '2020-06-12T15:05:36Z', '2020-06-11T04:16:33Z', '2020-06-18T19:14:43Z', '2020-08-08T07:36:25Z', '2020-06-03T13:10:11Z', '2020-07-06T16:19:56Z', '2020-08-21T18:59:01Z', '2020-12-04T09:31:29Z', '2020-05-31T13:26:11Z', '2020-06-10T03:19:33Z', '2020-06-10T21:57:47Z', '2020-06-05T13:15:40Z', '2020-06-12T15:05:35Z', '2020-06-08T13:16:05Z', '2020-06-08T14:21:41Z', '2020-07-30T15:21:38Z', '2020-06-08T13:23:41Z', '2020-06-10T03:17:21Z', '2020-06-06T20:38:45Z', '2020-06-11T19:01:28Z', '2020-05-31T13:36:35Z', '2020-06-08T13:16:05Z', '2020-06-08T14:21:41Z', '2020-05-31T13:36:35Z', '2020-06-15T21:15:54Z', '2020-06-10T03:17:21Z', '2020-06-08T13:19:54Z', '2020-05-31T15:53:18Z', '2020-06-02T13:17:37Z', '2020-06-07T10:57:26Z', '2020-06-08T12:12:54Z', '2020-11-11T20:29:51Z', '2020-06-12T15:18:56Z', '2020-06-09T14:40:49Z', '2020-10-02T15:14:41Z', '2020-06-10T16:56:18Z', '2020-06-08T13:22:35Z', '2020-06-10T21:30:06Z', '2020-06-11T04:16:33Z', '2020-06-10T17:00:57Z', '2020-06-10T21:30:06Z', '2020-05-31T13:26:11Z', '2020-06-03T13:12:16Z', '2020-06-10T03:17:21Z', '2020-05-31T21:59:57Z', '2020-06-03T13:12:16Z', '2020-05-30T20:05:36Z', '2020-06-08T20:11:06Z', '2020-06-22T04:38:35Z', '2020-12-05T02:31:03Z', '2020-06-04T14:42:10Z', '2020-06-11T04:16:33Z', '2020-07-01T17:11:44Z', '2020-06-08T13:19:54Z', '2020-10-05T08:10:18Z', '2020-06-03T13:10:11Z', '2020-06-10T03:17:21Z', '2020-05-31T22:01:23Z', '2020-06-08T12:11:35Z', '2020-06-02T13:17:37Z', '2020-05-31T16:40:33Z', '2020-06-12T01:40:39Z', '2020-05-30T20:12:46Z', '2020-06-08T13:16:05Z', '2020-06-03T21:14:48Z', '2020-06-24T02:50:37Z', '2020-05-29T02:30:30Z', '2020-06-08T13:23:41Z', '2020-06-01T16:02:51Z', '2020-06-10T03:13:47Z', '2020-06-02T20:06:38Z', '2020-08-12T19:45:54Z', '2020-06-06T17:56:41Z', '2020-05-30T20:05:36Z', '2020-06-10T03:17:21Z', '2020-06-07T10:57:26Z', '2020-06-22T12:35:05Z', '2020-05-30T20:05:36Z', '2020-06-06T23:33:40Z', '2020-06-03T13:06:08Z', '2020-10-11T21:45:22Z']\n"
     ]
    }
   ],
   "source": [
    "# Query 10 images of \"black lives matter\" in date of 2020 may to 2020 december\n",
    "json_response = query_in_date_range(\"black lives matter\", \"2020-05-01\", \"2020-12-31\", 100)\n",
    "# Perform check on the dates of the images \n",
    "#print(list_of_dates_of_images(json_response))\n",
    "# Download images of the above 10 images\n",
    "downloaded_files = download_images_from_json(json_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
